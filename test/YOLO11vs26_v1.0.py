import cv2
import time
import torch
import os
import pandas as pd
from pathlib import Path
from ultralytics import YOLO
from tqdm import tqdm

# 1. ê²½ë¡œ ë° ê¸°ë³¸ ì„¤ì •
DATA_DIR = Path("/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/data")
YOLO11_PATH = DATA_DIR / "checkpoints/YOLO/" / "yolo11m.pt"
YOLO26_PATH = DATA_DIR / "checkpoints/YOLO/" / "yolo26m.pt"
YOLO11_POSE_PATH = DATA_DIR / "checkpoints/YOLO/" / "yolo11m-pose.pt"
YOLO26_POSE_PATH = DATA_DIR / "checkpoints/YOLO/" / "yolo26m-pose.pt"

# ë©”íƒ€ë°ì´í„° ë¡œë“œ
metadata_path = DATA_DIR / "metadata.csv"
if not metadata_path.exists():
    raise FileNotFoundError("metadata.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
df = pd.read_csv(metadata_path)

# 2. GPU ì¥ì¹˜ ì„¤ì •
device = 0 if torch.cuda.is_available() else 'cpu'
if device == 0:
    torch.cuda.set_device(device)
    print(f"âœ… GPU ê°€ì† í™œì„±í™”: {torch.cuda.get_device_name(0)}")

# 3. ëª¨ë¸ ë¡œë“œ (ë£¨í”„ ì™¸ë¶€ì—ì„œ ë‹¨ í•œ ë²ˆë§Œ ìˆ˜í–‰í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤)
print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘... (í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤)")
model_info = [
    {"name": "YOLO11m", "path": str(YOLO11_PATH)},
    {"name": "YOLO26m", "path": str(YOLO26_PATH)},
    {"name": "YOLO11m-Pose", "path": str(YOLO11_POSE_PATH)},
    {"name": "YOLO26m-Pose", "path": str(YOLO26_POSE_PATH)}
]
# ëª¨ë¸ì„ GPUë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.
models = [YOLO(m["path"]).to(device) for m in model_info]
print("ğŸš€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# 4. Target ë£¨í”„ ì‹¤í–‰ (ì˜ˆ: 0ë¶€í„° 32ê¹Œì§€)
# ì›í•˜ì‹œëŠ” ë²”ìœ„ë¡œ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤: range(0, 32) -> 0ë¶€í„° 31ê¹Œì§€
TARGET_START = 35
TARGET_END = 40

for target_idx in range(TARGET_START, TARGET_END):
    try:
        # ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ í™•ì¸
        if target_idx not in df.index:
            print(f"âš ï¸ Target {target_idx}: ë©”íƒ€ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        COMMON_PATH = df.loc[target_idx, "common_path"]
        
        # ì…ë ¥ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        FRAME_DIR = DATA_DIR / "1_FRAME" / COMMON_PATH
        OUTPUT_DIR = DATA_DIR / "test" / COMMON_PATH
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # í”„ë ˆì„ íŒŒì¼ í™•ë³´
        frame_files = sorted([f for f in FRAME_DIR.glob("*.jpg")])
        if not frame_files:
            print(f"âš ï¸ Target {target_idx} ({COMMON_PATH}): í”„ë ˆì„ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # ë¹„ë””ì˜¤ ì €ì¥ ì„¤ì •
        sample_img = cv2.imread(str(frame_files[0]))
        h, w = sample_img.shape[:2]
        
        video_filename = f"Comparison_v1.0.mp4"
        output_video_path = str(OUTPUT_DIR / video_filename)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (w * 2, h * 2))
        
        print(f"\nâ–¶ï¸ [Target {target_idx}] ë¶„ì„ ì‹œì‘: {len(frame_files)} Frames")
        print(f"   ğŸ“‚ ì €ì¥ ê²½ë¡œ: {output_video_path}")

        # --- í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„ (tqdm ì ìš©) ---
        # descì— í˜„ì¬ target ë²ˆí˜¸ë¥¼ í‘œì‹œí•˜ì—¬ ì§„í–‰ ìƒí™©ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.
        for frame_path in tqdm(frame_files, desc=f"Target {target_idx}", unit="frame"):
            input_img = cv2.imread(str(frame_path))
            processed_results = []

            for i, model in enumerate(models):
                # ì •ë°€ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ GPU ë™ê¸°í™”
                if device != 'cpu': torch.cuda.synchronize()
                
                start_t = time.perf_counter()
                
                # Tracking ìˆ˜í–‰ (persist=Trueë¡œ ID ìœ ì§€)
                # imgsz=640ìœ¼ë¡œ ê³ ì •í•˜ì—¬ ì¶”ë¡  ì†ë„ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.
                result = model.track(input_img, imgsz=640, classes=[0], device=device, 
                                     persist=True, verbose=False)[0]
                
                if device != 'cpu': torch.cuda.synchronize()
                end_t = time.perf_counter()
                
                fps = 1.0 / (end_t - start_t)
                
                # ì‹œê°í™” (Bounding Box + ID + Skeleton)
                res_frame = result.plot()
                
                # ì •ë³´ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
                display_text = f"{model_info[i]['name']} | FPS: {fps:.1f}"
                font_scale, thickness = 1.0, 2
                text_size = cv2.getTextSize(display_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]
                
                tx, ty = w - text_size[0] - 20, 45 
                # ê°€ë…ì„±ì„ ìœ„í•œ ê²€ì€ìƒ‰ ë°°ê²½ ë°•ìŠ¤
                cv2.rectangle(res_frame, (tx - 5, ty - text_size[1] - 5), (tx + text_size[0] + 5, ty + 5), (0, 0, 0), -1)
                # ë…¹ìƒ‰ í…ìŠ¤íŠ¸
                cv2.putText(res_frame, display_text, (tx, ty), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), thickness, cv2.LINE_AA)
                
                processed_results.append(res_frame)

            # 4ë¶„í•  í™”ë©´ ë³‘í•© (2x2 Grid)
            top_row = cv2.hconcat([processed_results[0], processed_results[1]])
            bottom_row = cv2.hconcat([processed_results[2], processed_results[3]])
            final_frame = cv2.vconcat([top_row, bottom_row])
            
            out.write(final_frame)

        # í˜„ì¬ Target ì‘ì—… ì¢…ë£Œ ë° ë¦¬ì†ŒìŠ¤ í•´ì œ
        out.release()
        
    except Exception as e:
        print(f"\nâŒ [Error] Target {target_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ê°€ ë‚˜ë„ ë‹¤ìŒ Targetìœ¼ë¡œ ë„˜ì–´ê°€ë„ë¡ continue ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        if 'out' in locals(): out.release()
        continue

print("\nğŸ‰ ëª¨ë“  Targetì— ëŒ€í•œ ë¶„ì„ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")